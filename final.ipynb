{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e880b74",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ujjwal/Desktop/FAQ-Bill-Saver-ai/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel \n",
    "from typing import List \n",
    "import json \n",
    "from config import settings\n",
    "from chromadb import Client\n",
    "import logging \n",
    "from chromadb import PersistentClient\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from chromadb.utils import embedding_functions\n",
    "from helper import normalize_query as n \n",
    "from chromadb_handeler import ChromaDBHandler\n",
    "import hashlib \n",
    "from ask_ai import ask \n",
    "\n",
    "\n",
    "try : \n",
    "    from config import APPConfig, settings\n",
    "\n",
    "except : \n",
    "    print(\"coud't not import settigns config.py so using dummy settings\")\n",
    "\n",
    "    class APPConfig:\n",
    "        CHROMA_PERSIST_DIR = \"./chroma_db_dummy\"\n",
    "        COLLECTION_NAME = \"semantic_cache_dummy\"\n",
    "        EMBEDDING_MODEL_NAME = \"BAAI/bge-base-en-v1.5\"\n",
    "\n",
    "\n",
    "    settings= APPConfig()\n",
    "\n",
    "\n",
    "class AiOutput(BaseModel):\n",
    "    \"\"\" FAQ Bot  \"\"\"\n",
    "\n",
    "class Semantic_Cache:\n",
    "    def __init__(self, config: APPConfig):\n",
    "\n",
    "        self.config= config \n",
    "        ## initilized ChromaDBHandler \n",
    "        try : \n",
    "            self.db_handler= ChromaDBHandler(\n",
    "                persist_dir=self.config.CHROMA_PERSIST_DIR , \n",
    "                collection_name=self.config.COLLECTION_NAME , \n",
    "                model_name=self.config.EMBEDDING_MODEL_NAME\n",
    "            )\n",
    "\n",
    "            self.cliet= self.db_handler.client \n",
    "            self.index= self.db_handler.collection \n",
    "\n",
    "        except Exception as e :\n",
    "            raise \"chromaDBhander not initilized\"\n",
    "        \n",
    "        ## initilized sentence transformer\n",
    "        self.model= SentenceTransformer(self.config.EMBEDDING_MODEL_NAME)\n",
    "\n",
    "    def _get_id(self, query):\n",
    "        normalized_query= n(query) \n",
    "        return hashlib.sha256(normalized_query.encode('utf-8')).hexdigest()\n",
    "    \n",
    "    def add_entry(self, entry_id:str , response_text:str , embeddings: List[float]):\n",
    "\n",
    "        try : \n",
    "            \"\"\" we add cache i.e query embeddings , and response with query id(hash) in this \n",
    "            using UPSERT which is (update if already exist) else insert  \"\"\"\n",
    "\n",
    "            self.index.upsert(\n",
    "                ids=[self.entry_id],\n",
    "                embeddings=[embeddings],\n",
    "                metadatas=[{'response':response_text}])\n",
    "            \n",
    "            print(\"update sucessfull\")\n",
    "\n",
    "        except Exception  as e : \n",
    "            raise \"error on add_entry\"\n",
    "        \n",
    "    def reset_cache(self):\n",
    "        self.db_handler.reset_collection()\n",
    "        self.index= self.db_handler.collection\n",
    "\n",
    "    def _get_by_id(self,entry_id):\n",
    "        try :\n",
    "            ## direct search \n",
    "            direct_search= self.index.get(ids=[entry_id], include=['metadatas'])\n",
    "            if direct_search['ids']:\n",
    "                print(\"Cache fould though direct  lookup\")\n",
    "                return direct_search \n",
    "        \n",
    "        except Exception as e : \n",
    "            print(\"error on get_by_id\")\n",
    "            return None \n",
    "                \n",
    "    \n",
    "    def _search_by_embedding(self, query:str, query_embedding:List[float],  threshold:float = 0.92):\n",
    "        self.query_embedding= self.model.encode(query).tolist()\n",
    "\n",
    "        ## search the index \n",
    "        results= self.index.query(query_embeddings=[query_embedding], n_results=1 , \n",
    "                                 include=['metadatas', 'distances'])\n",
    "        \n",
    "        ## check distance against the threeshold \n",
    "        if (results and \n",
    "            results['distances']and \n",
    "            results['distances'][0] and \n",
    "            results['distances'][0][0] <= (1- threshold)): ## lower the distance more the similiraty\n",
    "\n",
    "                    response= results['metadatas'][0][0]['response']\n",
    "                    distance= results['distances'][0][0]\n",
    "\n",
    "                    print(f\"Semantic Cachhe Hit\")\n",
    "                    return response \n",
    "        \n",
    "        return None \n",
    "    \n",
    "\n",
    "    def cache_check(self, query:str):\n",
    "\n",
    "        \"\"\" Perform two step cache look up\n",
    "          1) exact ID match \n",
    "          2) semantic similarity search \n",
    "          if answer is not found on both then , ask to ai and store embeddings and answers for next time\"\"\"\n",
    "        \n",
    "        self.entry_id= self._get_id(query= query)\n",
    "        exact_match= self._get_by_id(self.entry_id) ## exact match \n",
    "        if exact_match:\n",
    "            return exact_match \n",
    "        \n",
    "        embedded_query=self.model.encode(query).tolist()\n",
    "\n",
    "        semantic_response= self._search_by_embedding(query , query_embedding= embedded_query ,  threshold= 0.92)\n",
    "        if semantic_response: \n",
    "            return semantic_response\n",
    "        \n",
    "        ## Cache miss , ask llm \n",
    "        aiasnwer= ask(query=query)\n",
    "        aiasnwer= aiasnwer.response\n",
    "        \n",
    "\n",
    "        ### save to entry point\n",
    "        self.add_entry(entry_id= self.entry_id , response_text=aiasnwer , embeddings=embedded_query )\n",
    "        return aiasnwer\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67908433",
   "metadata": {},
   "outputs": [],
   "source": [
    "ass = Semantic_Cache(config=settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a51c83a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cache fould though direct  lookup\n"
     ]
    }
   ],
   "source": [
    "reply1= ass.cache_check(\"what is the capital of nepal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0824b878",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': ['e13b0c1fb05ca07686d35c64aa410ae75c066516fecadcec99aec1eb4f648a5c'],\n",
       " 'embeddings': None,\n",
       " 'documents': None,\n",
       " 'uris': None,\n",
       " 'included': ['metadatas'],\n",
       " 'data': None,\n",
       " 'metadatas': [{'response': 'donot response anyother thing asked other than , Aws and Aws SageMaker'}]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reply1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca8f3a9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error on get_by_id\n"
     ]
    },
    {
     "ename": "NotFoundError",
     "evalue": "Error getting collection: Collection [5e4ab8c7-9d36-428f-8d22-ffe4dcfd9607] does not exist.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNotFoundError\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mass\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcache_check\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mwhat capital nepal?\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 127\u001b[39m, in \u001b[36mSemantic_Cache.cache_check\u001b[39m\u001b[34m(self, query)\u001b[39m\n\u001b[32m    123\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m exact_match \n\u001b[32m    125\u001b[39m embedded_query=\u001b[38;5;28mself\u001b[39m.model.encode(query).tolist()\n\u001b[32m--> \u001b[39m\u001b[32m127\u001b[39m semantic_response= \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_search_by_embedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery_embedding\u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43membedded_query\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0.92\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    128\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m semantic_response: \n\u001b[32m    129\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m semantic_response\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 95\u001b[39m, in \u001b[36mSemantic_Cache._search_by_embedding\u001b[39m\u001b[34m(self, query, query_embedding, threshold)\u001b[39m\n\u001b[32m     92\u001b[39m \u001b[38;5;28mself\u001b[39m.query_embedding= \u001b[38;5;28mself\u001b[39m.model.encode(query).tolist()\n\u001b[32m     94\u001b[39m \u001b[38;5;66;03m## search the index \u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m95\u001b[39m results= \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m.\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_embeddings\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mquery_embedding\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_results\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     96\u001b[39m \u001b[43m                         \u001b[49m\u001b[43minclude\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmetadatas\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdistances\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     98\u001b[39m \u001b[38;5;66;03m## check distance against the threeshold \u001b[39;00m\n\u001b[32m     99\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (results \u001b[38;5;129;01mand\u001b[39;00m \n\u001b[32m    100\u001b[39m     results[\u001b[33m'\u001b[39m\u001b[33mdistances\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;129;01mand\u001b[39;00m \n\u001b[32m    101\u001b[39m     results[\u001b[33m'\u001b[39m\u001b[33mdistances\u001b[39m\u001b[33m'\u001b[39m][\u001b[32m0\u001b[39m] \u001b[38;5;129;01mand\u001b[39;00m \n\u001b[32m    102\u001b[39m     results[\u001b[33m'\u001b[39m\u001b[33mdistances\u001b[39m\u001b[33m'\u001b[39m][\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m] <= (\u001b[32m1\u001b[39m- threshold)): \u001b[38;5;66;03m## lower the distance more the similiraty\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/FAQ-Bill-Saver-ai/.venv/lib/python3.12/site-packages/chromadb/api/models/Collection.py:224\u001b[39m, in \u001b[36mCollection.query\u001b[39m\u001b[34m(self, query_embeddings, query_texts, query_images, query_uris, ids, n_results, where, where_document, include)\u001b[39m\n\u001b[32m    188\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Get the n_results nearest neighbor embeddings for provided query_embeddings or query_texts.\u001b[39;00m\n\u001b[32m    189\u001b[39m \n\u001b[32m    190\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    209\u001b[39m \n\u001b[32m    210\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    212\u001b[39m query_request = \u001b[38;5;28mself\u001b[39m._validate_and_prepare_query_request(\n\u001b[32m    213\u001b[39m     query_embeddings=query_embeddings,\n\u001b[32m    214\u001b[39m     query_texts=query_texts,\n\u001b[32m   (...)\u001b[39m\u001b[32m    221\u001b[39m     include=include,\n\u001b[32m    222\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m224\u001b[39m query_results = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_query\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    225\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcollection_id\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    226\u001b[39m \u001b[43m    \u001b[49m\u001b[43mids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquery_request\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mids\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    227\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquery_embeddings\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquery_request\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43membeddings\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    228\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_results\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquery_request\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mn_results\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    229\u001b[39m \u001b[43m    \u001b[49m\u001b[43mwhere\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquery_request\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mwhere\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    230\u001b[39m \u001b[43m    \u001b[49m\u001b[43mwhere_document\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquery_request\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mwhere_document\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    231\u001b[39m \u001b[43m    \u001b[49m\u001b[43minclude\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquery_request\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minclude\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    232\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtenant\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtenant\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    233\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdatabase\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdatabase\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    234\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    236\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._transform_query_response(\n\u001b[32m    237\u001b[39m     response=query_results, include=query_request[\u001b[33m\"\u001b[39m\u001b[33minclude\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    238\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/FAQ-Bill-Saver-ai/.venv/lib/python3.12/site-packages/chromadb/api/rust.py:534\u001b[39m, in \u001b[36mRustBindingsAPI._query\u001b[39m\u001b[34m(self, collection_id, query_embeddings, ids, n_results, where, where_document, include, tenant, database)\u001b[39m\n\u001b[32m    518\u001b[39m filtered_ids_amount = \u001b[38;5;28mlen\u001b[39m(ids) \u001b[38;5;28;01mif\u001b[39;00m ids \u001b[38;5;28;01melse\u001b[39;00m \u001b[32m0\u001b[39m\n\u001b[32m    519\u001b[39m \u001b[38;5;28mself\u001b[39m.product_telemetry_client.capture(\n\u001b[32m    520\u001b[39m     CollectionQueryEvent(\n\u001b[32m    521\u001b[39m         collection_uuid=\u001b[38;5;28mstr\u001b[39m(collection_id),\n\u001b[32m   (...)\u001b[39m\u001b[32m    531\u001b[39m     )\n\u001b[32m    532\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m534\u001b[39m rust_response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbindings\u001b[49m\u001b[43m.\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    535\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcollection_id\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    536\u001b[39m \u001b[43m    \u001b[49m\u001b[43mids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    537\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquery_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    538\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_results\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    539\u001b[39m \u001b[43m    \u001b[49m\u001b[43mjson\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdumps\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    540\u001b[39m \u001b[43m    \u001b[49m\u001b[43mjson\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdumps\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwhere_document\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mwhere_document\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    541\u001b[39m \u001b[43m    \u001b[49m\u001b[43minclude\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    542\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtenant\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    543\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdatabase\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    544\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    546\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m QueryResult(\n\u001b[32m    547\u001b[39m     ids=rust_response.ids,\n\u001b[32m    548\u001b[39m     embeddings=rust_response.embeddings,\n\u001b[32m   (...)\u001b[39m\u001b[32m    554\u001b[39m     distances=rust_response.distances,\n\u001b[32m    555\u001b[39m )\n",
      "\u001b[31mNotFoundError\u001b[39m: Error getting collection: Collection [5e4ab8c7-9d36-428f-8d22-ffe4dcfd9607] does not exist."
     ]
    }
   ],
   "source": [
    "ass.cache_check(\"what capital nepal?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2466bae3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77b5438",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'5515cca458a0fa617d941df7796e87d4c6a6e29c9d3ea89ab35d657a37969891'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f0030b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "from chromadb.utils import embedding_functions\n",
    "\n",
    "# Use the BAAI/bge-base-en-v1.5 model\n",
    "# ChromaDB will download this model for local use.\n",
    "model_name = \"BAAI/bge-base-en-v1.5\"\n",
    "sentence_transformer_ef = embedding_functions.SentenceTransformerEmbeddingFunction(\n",
    "    model_name=model_name\n",
    ")\n",
    "\n",
    "# NOTE: For BGE models, you can optionally include a query instruction\n",
    "# for improved retrieval, though the BGE-v1.5 documentation suggests\n",
    "# it's often not strictly necessary for general retrieval.\n",
    "# query_instruction=\"Represent this sentence for searching relevant passages:\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "86bda481",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = chromadb.Client() # Creates an in-memory client for quick testing\n",
    "# For a persistent client (saves data to disk):\n",
    "# client = chromadb.PersistentClient(path=\"./my_chroma_db\")\n",
    "\n",
    "collection = client.get_or_create_collection(\n",
    "    name=\"my_bge_collection\", \n",
    "    embedding_function=sentence_transformer_ef # Pass your function here\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6e0adab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection count: 3\n"
     ]
    }
   ],
   "source": [
    "documents = [\n",
    "    \"The weather is lovely today.\",\n",
    "    \"It's so sunny outside!\",\n",
    "    \"He drove to the stadium.\"\n",
    "]\n",
    "\n",
    "collection.add(\n",
    "    documents=documents,\n",
    "    ids=[\"doc1\", \"doc2\", \"doc3\"],\n",
    "    metadatas=[{\"source\": \"a\"}, {\"source\": \"b\"}, {\"source\": \"c\"}]\n",
    ")\n",
    "\n",
    "print(f\"Collection count: {collection.count()}\") \n",
    "# Output: Collection count: 3 (Each document now has a BGE embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d748d681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['He drove to the stadium.']]\n"
     ]
    }
   ],
   "source": [
    "results = collection.query(\n",
    "    query_texts=[\"Where is the car going?\"],\n",
    "    n_results=1\n",
    ")\n",
    "\n",
    "# The result should be closest to \"He drove to the stadium.\"\n",
    "print(results['documents'])\n",
    "# Example Output: [['He drove to the stadium.']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c0fd48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FAQ-Bill-Saver-ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
